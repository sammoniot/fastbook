{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c621e7650d4943",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Visualizing your NLP data: An Orientation with a Sorted Bar Plot\n",
    "\n",
    "* This homework is building on cells from the previous assignment, and then moving on to show you how to visualize the data.\n",
    "* We'll start with the usual **pip installs** you need:\n",
    "    * **pip install numpy**\n",
    "    * **pip install seaborn**\n",
    "    * **pip install matplotlib**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/thinc/compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "/usr/local/lib/python3.11/site-packages/thinc/compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# !pip install saxonche\n",
    "# !pip install pathlib\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import re as regex\n",
    "# re lets us work with regular expressions in Python\n",
    "from saxonche import PySaxonProcessor\n",
    "from os import getcwd\n",
    "# this lets us retrieve the current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204f234-ebbb-4867-9cb2-d3494379b392",
   "metadata": {},
   "source": [
    "Remember the spaCy language models? Let's try loading loading the large one to get the maximum amount of information from it! \n",
    "There's a lot we can experiment with from spaCy, so here's a link to the documentation for our ready reference:\n",
    "<https://spacy.io/usage/spacy-101> \n",
    "\n",
    "We're going to start by just reviewing its POS (part of speech) and NER (named entity recognition) taggers to see what we can see in your project files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337c9b20-f094-4cc2-9c51-c9ce642a81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.cli.download(\"en_core_web_lg\")\n",
    "# ONLY NEED ABOVE LINE ONCE. REMEMBER: COMMENT OUT THE ABOVE LINE THE NEXT TIME YOU RUN THIS.\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3aa2a5-fef7-40d0-921a-668b9021f09c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Okay, let's explore some project files!\n",
    "We've loaded the XML directory prepared by the Futurama team for our example here. \n",
    "\n",
    "* If you have some basic XML right now, like the Futurama team has prepared, we can easily scope in tagged sections of your collection. Swap out the Futurama collection with yours, and adjust the Python code below accordingly.\n",
    "* If you don't have XML at this point, you can work around this over text files, or just explore the Futurama collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e5ed67e-3a24-49d0-8a92-526e941ccebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE SOME FILE PATHS FOR INPUT, AND (ONCE WE'RE READY) OUTPUT\n",
    "InputPath = 'futurama-xml'\n",
    "OutputPath = 'testOutput' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842d99e-4b58-4681-aa39-2ff13aaabde0",
   "metadata": {},
   "source": [
    "# You can SKIP the next (XPath) code block for now \n",
    "(We're leaving it for review: we'll find a good use for it later).\n",
    "\n",
    "The next cell demonstrates the xpath() function, set up to run over individual files.\n",
    "Let's look at how it returns information about distinct values of speakers. We're exploring distinct-values() and count() functions here. Try removing them and putting them back to see what the effect of distinct-values() is on the count. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84065536-1328-4c31-887b-57ea4576301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTextFiles(InputPath):\n",
    "    # This function uses XPath to read the XML input\n",
    "    for file in os.listdir(InputPath):\n",
    "        if file.endswith('.xml'):\n",
    "            filepath = f\"{InputPath}/{file}\"\n",
    "            with PySaxonProcessor(license=False) as proc:\n",
    "                xml = open(filepath, encoding='utf-8').read()\n",
    "                # ebb: Here we apply the Saxon processor to read files with XPath.\n",
    "                xp = proc.new_xpath_processor()\n",
    "                node = proc.parse_xml(xml_text=xml)\n",
    "                xp.set_context(xdm_item=node)\n",
    "\n",
    "                # From here on, we select the string that Python will send to NLP. \n",
    "                # xpath = xp.evaluate('//your/xpath/here')\n",
    "                xpath = xp.evaluate('//speak/@who => distinct-values() => sort()')\n",
    "                count = xp.evaluate('//speak/@who => distinct-values() => count()')\n",
    "                string = str(xpath)\n",
    "                print(xpath)\n",
    "                # xpath is going to go file by file.\n",
    "             \n",
    "readTextFiles(InputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4454e36-c2af-4d35-ad60-964a78567779",
   "metadata": {},
   "source": [
    "## XQuery Blocks\n",
    "Review: XQuery is what we want to use to help read data from across a whole directory, or \"corpus\" collection of files. \n",
    "XQuery can be written as a separate file (with .xql or .xquery extension) in oXygen over a directory. But we will find it more useful \n",
    "to apply it in Python if we're working on natural language processing applications. \n",
    "\n",
    "### Setting up XQuery in Python \n",
    "We use the same \"boilerplate\" PySaxonProcessor lines, but switch from xpath to the xquery processor.\n",
    "\n",
    "\n",
    "Requirements: \n",
    "* We need all the xq lines to plug this processing into Python. You can use this code as a starter for your projects.\n",
    "* The XQuery script is written inside a quoted block in the set_query_content() function that needs to take a quoted string, just like in the cell below.\n",
    "* We need the run_query_to_value() function to execuit the script we're writing.\n",
    "  \n",
    "\n",
    "**Reading the collection**: We're setting this up to read a `collection()` function, which is a directory of XML files. \n",
    "**Writing XQuery**: This involves setting simple variables equal to xpath expressions. XQuery variables are defined with a `$`.\n",
    "**XQuery Comments**: look like sideways smiley faces. `(: I'm an XQuery comment :)`\n",
    "\n",
    "Let's take a look:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5f62be-51be-472c-9ce1-6fbe9143d141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaxonC-HE 12.3 from Saxonica\n",
      "\"5-EYES\"\n",
      "\"AARON JR\"\n",
      "\"AARON SR\"\n",
      "\"AD ROCK\"\n",
      "\"ADLAI\"\n",
      "\"AHAB\"\n",
      "\"AKI\"\n",
      "\"ALBERT\"\n",
      "\"ALBRIGHTBOT\"\n",
      "\"ALEX\"\n",
      "\"ALIEN\"\n",
      "\"ALIENS\"\n",
      "\"ALKAZAR\"\n",
      "\"ALL\"\n",
      "\"ALPHABOT\"\n",
      "\"AMAZONIAN\"\n",
      "\"AMAZONIANS\"\n",
      "\"AMBASSADOR MOIVIN\"\n",
      "\"AMY\"\n",
      "\"AMY 1\"\n",
      "\"AMY 420\"\n",
      "\"ANDERSON\"\n",
      "\"ANDREW\"\n",
      "\"ANDY\"\n",
      "\"ANGLEYNE\"\n",
      "\"ANNOUNCER\"\n",
      "\"ANNOUNCER #1\"\n",
      "\"ANNOUNCER #2\"\n",
      "\"ANTONIO\"\n",
      "\"ARACHNEON\"\n",
      "\"ARMY ROBOT\"\n",
      "\"ARTHUR\"\n",
      "\"ATILLA THE HUN\"\n",
      "\"AUCTIONEER\"\n",
      "\"AUDIENCE\"\n",
      "\"AUSTRALIAN GUY\"\n",
      "\"AUTOPILOT\"\n",
      "\"BABE\"\n",
      "\"BAILIFF\"\n",
      "\"BAILLIF\"\n",
      "\"BARBADOS SLIM\"\n",
      "\"BARKER\"\n",
      "\"BARMAN\"\n",
      "\"BARRIERBOT #1\"\n",
      "\"BARRIERBOT #2\"\n",
      "\"BARTENDER\"\n",
      "\"BARTENDERBOT\"\n",
      "\"BEASTIE BOYS\"\n",
      "\"BECK\"\n",
      "\"BEE\"\n",
      "\"BEELER\"\n",
      "\"BEES\"\n",
      "\"BENDER\"\n",
      "\"BENDER 1\"\n",
      "\"BENDER 1729\"\n",
      "\"BENDER AND BECK\"\n",
      "\"BENDER AND BENDER 1\"\n",
      "\"BENDER FIGURINE\"\n",
      "\"BENDING UNIT\"\n",
      "\"BESERK\"\n",
      "\"BETABOT\"\n",
      "\"BETAMAX PLAYER\"\n",
      "\"BIDDER #1\"\n",
      "\"BIDDER #2\"\n",
      "\"BIG BRAIN\"\n",
      "\"BIG EARED MUTANT\"\n",
      "\"BIG MOUTHED MUTANT\"\n",
      "\"BIKE THIEF\"\n",
      "\"BILL\"\n",
      "\"BILLIONAIREBOT\"\n",
      "\"BILLY\"\n",
      "\"BLUE ELDER\"\n",
      "\"BOLT\"\n",
      "\"BONT\"\n",
      "\"BOOTH VOICE\"\n",
      "\"BOY\"\n",
      "\"BRAIN #1\"\n",
      "\"BRAIN #2\"\n",
      "\"BRAIN #3\"\n",
      "\"BRAIN BALL #1\"\n",
      "\"BRAIN BALL #2\"\n",
      "\"BRET\"\n",
      "\"BROKERBOT #1\"\n",
      "\"BROKERBOT #2\"\n",
      "\"BROKERBOT #3\"\n",
      "\"BUBBLEGUM TATE\"\n",
      "\"BULLY\"\n",
      "\"BUREACRATS\"\n",
      "\"BUSH SR\"\n",
      "\"BUTCH\"\n",
      "\"BUTLER\"\n",
      "\"BUTT TATTOOS\"\n",
      "\"CADDY\"\n",
      "\"CALCULON\"\n",
      "\"CAMERA\"\n",
      "\"CAMPAIGN MANAGER\"\n",
      "\"CAPTAIN\"\n",
      "\"CARD\"\n",
      "\"CARTER\"\n",
      "\"CARTRIDGE UNIT\"\n",
      "\"CASTING DIRECTOR\"\n",
      "\"CATERPILLAR ALIEN\"\n",
      "\"CAVEMAN\"\n",
      "\"CEILING FAN\"\n",
      "\"CHAIN SMOKER\"\n",
      "\"CHAIR\"\n",
      "\"CHANG\"\n",
      "\"CHAZ\"\n",
      "\"CHEECH\"\n",
      "\"CHEF\"\n",
      "\"CHET\"\n",
      "\"CHILD\"\n",
      "\"CHRISSY\"\n",
      "\"CLAMPS\"\n",
      "\"CLARK\"\n",
      "\"CLEARCUTTER\"\n",
      "\"CLERK\"\n",
      "\"CLINTON\"\n",
      "\"COFFEE MACHINE\"\n",
      "\"COILETTE\"\n",
      "\"COLONEL\"\n",
      "\"COMMENTATOR\"\n",
      "\"COMMISSIONER\"\n",
      "\"COMPUTER VOICE\"\n",
      "\"CONGREGATION\"\n",
      "\"CONSPIRACY NUTTER\"\n",
      "\"CONSTRUCTIONBOT\"\n",
      "\"COOL\"\n",
      "\"COSELL\"\n",
      "\"COSMETOLOGIST\"\n",
      "\"COUNTESS\"\n",
      "\"COWBOY\"\n",
      "\"CRACK ADDICT\"\n",
      "\"CRATER FACE\"\n",
      "\"CREWMAN\"\n",
      "\"CRONKITE\"\n",
      "\"CROUPIER\"\n",
      "\"CROW T\"\n",
      "\"CROWD\"\n",
      "\"CRUSHINATOR\"\n",
      "\"CRYOGENISIST\"\n",
      "\"CRYSTAL\"\n",
      "\"CUBERT\"\n",
      "\"CURLY JOE\"\n",
      "\"CUSTOMER\"\n",
      "\"CYCLOPIAN\"\n",
      "\"CYCLOPS\"\n",
      "\"CYGNOID #2\"\n",
      "\"CYGNOID #3\"\n",
      "\"CYGNOID MAN\"\n",
      "\"CYGNOID WOMAN\"\n",
      "\"CYLON\"\n",
      "\"CYLON AND GARFUNKEL\"\n",
      "\"DAISY MAE 128K\"\n",
      "\"DARK WIZARD\"\n",
      "\"DECAPOD EMPEROR\"\n",
      "\"DECAPOD MAN #1\"\n",
      "\"DECAPOD MAN #2\"\n",
      "\"DECAPOD MANM #1\"\n",
      "\"DECAPOD WOMAN #1\"\n",
      "\"DECAPOD WOMAN #2\"\n",
      "\"DECAPOD WOMAN #3\"\n",
      "\"DECAPODIAN MAN\"\n",
      "\"DECAPODIAN WOMAN\"\n",
      "\"DEEP BLUE\"\n",
      "\"DESTRUCTOR\"\n",
      "\"DIRECTOR\"\n",
      "\"DIXIE\"\n",
      "\"DJ\"\n",
      "\"DOCTOR\"\n",
      "\"DOCTOR #1\"\n",
      "\"DOCTOR #2\"\n",
      "\"DOCTORBOT\"\n",
      "\"DOLE\"\n",
      "\"DOLL\"\n",
      "\"DONBOT\"\n",
      "\"DONKEY KONG\"\n",
      "\"DONOVAN\"\n",
      "\"DOORMAN\"\n",
      "\"DOUBLEDEAL\"\n",
      "\"DOUG\"\n",
      "\"DR PERCEPTRON\"\n",
      "\"DWAYNE\"\n",
      "\"DWIGHT\"\n",
      "\"EDNA\"\n",
      "\"EINSTEIN\"\n",
      "\"ELDERS\"\n",
      "\"ELZAR\"\n",
      "\"EMCEE\"\n",
      "\"EMOTITRON JR\"\n",
      "\"ENOS\"\n",
      "\"ENSIGN\"\n",
      "\"EVANS\"\n",
      "\"EVERYBODY\"\n",
      "\"EVERYONE\"\n",
      "\"EVIL LINCOLN\"\n",
      "\"FANSWORTH\"\n",
      "\"FARMER\"\n",
      "\"FARMER #1\"\n",
      "\"FARMER #2\"\n",
      "\"FARNSOWRTH\"\n",
      "\"FARNSWORTH\"\n",
      "\"FARNSWORTH 1\"\n",
      "\"FARNSWORTH 420\"\n",
      "\"FARNSWORTH XVII\"\n",
      "\"FART MOB\"\n",
      "\"FATBOT\"\n",
      "\"FATHER\"\n",
      "\"FEMALE ANNOUNCER\"\n",
      "\"FEMALE SCIENTIST\"\n",
      "\"FEMALE VOICE\"\n",
      "\"FEMBOT\"\n",
      "\"FEMBOT #1\"\n",
      "\"FEMBOT #2\"\n",
      "\"FEMPUTER\"\n",
      "\"FENDER\"\n",
      "\"FIONA\"\n",
      "\"FISHY JOE\"\n",
      "\"FLABBY\"\n",
      "\"FLEXO\"\n",
      "\"FLORP\"\n",
      "\"FNOG\"\n",
      "\"FORD\"\n",
      "\"FOREIGNER\"\n",
      "\"FOREMAN\"\n",
      "\"FOX ANNOUNCER\"\n",
      "\"FRAKES\"\n",
      "\"FRAME #1\"\n",
      "\"FRAME #2\"\n",
      "\"FRANKIE\"\n",
      "\"FRANKLIN\"\n",
      "\"FRATBOT #1\"\n",
      "\"FRATBOT #2\"\n",
      "\"FRATBOT #3\"\n",
      "\"FRED\"\n",
      "\"FRENCH GUY\"\n",
      "\"FRIEDA WATERFALL\"\n",
      "\"FRY\"\n",
      "\"FRY 1\"\n",
      "\"FRY 1729\"\n",
      "\"FRY AND BENDER\"\n",
      "\"FRY AND ZOIDBERG\"\n",
      "\"FRY LEELA AND BENDER\"\n",
      "\"FUTURE FRY\"\n",
      "\"GALAXY\"\n",
      "\"GAMMABOT\"\n",
      "\"GARBAGE DISPOSAL\"\n",
      "\"GARFUNKEL\"\n",
      "\"GARY\"\n",
      "\"GAS\"\n",
      "\"GAY SAILOR\"\n",
      "\"GEARSHIFT\"\n",
      "\"GENERAL\"\n",
      "\"GENEWORKS WOMAN\"\n",
      "\"GEORGE MICHAEL\"\n",
      "\"GIANT BRAIN\"\n",
      "\"GILLMAN\"\n",
      "\"GIRL\"\n",
      "\"GLAB\"\n",
      "\"GLERMO\"\n",
      "\"GLURMO\"\n",
      "\"GOD\"\n",
      "\"GOPHER #1\"\n",
      "\"GOPHER #2\"\n",
      "\"GOPHERS\"\n",
      "\"GORE\"\n",
      "\"GORGAK\"\n",
      "\"GORILLAS\"\n",
      "\"GRADE 11\"\n",
      "\"GRADE 20\"\n",
      "\"GRADE 41\"\n",
      "\"GRADE 53\"\n",
      "\"GREEN ELDER\"\n",
      "\"GREETING CARD\"\n",
      "\"GRUMPY SNAIL\"\n",
      "\"GRUNKA LUNKA #1\"\n",
      "\"GRUNKA LUNKA #2\"\n",
      "\"GRUNKA LUNKAS\"\n",
      "\"GUARD\"\n",
      "\"GUARD #1\"\n",
      "\"GUARD #2\"\n",
      "\"GUARD #3\"\n",
      "\"GUARDBOT #1\"\n",
      "\"GUARDBOT #2\"\n",
      "\"GUARDBOT #3\"\n",
      "\"GUARDBOT #4\"\n",
      "\"GUARDS\"\n",
      "\"GUENTER\"\n",
      "\"GUS\"\n",
      "\"GUY\"\n",
      "\"GUY #1\"\n",
      "\"GUY #2\"\n",
      "\"GWEN\"\n",
      "\"GYGAX\"\n",
      "\"GYPSY\"\n",
      "\"HAIRBOT\"\n",
      "\"HAMMURABI\"\n",
      "\"HATTIE\"\n",
      "\"HAWKING\"\n",
      "\"HEATHER\"\n",
      "\"HEDONISMBOT\"\n",
      "\"HELPER\"\n",
      "\"HERMENTHOTIP\"\n",
      "\"HERMES\"\n",
      "\"HERMES 1\"\n",
      "\"HERMES 25\"\n",
      "\"HICK\"\n",
      "\"HIGH PRIEST\"\n",
      "\"HIPPIE #1\"\n",
      "\"HIPPIE #2\"\n",
      "\"HIPPIE #3\"\n",
      "\"HIPPIE #4\"\n",
      "\"HIPPIE #5\"\n",
      "\"HIPPIE #6\"\n",
      "\"HIROKI\"\n",
      "\"HOBO\"\n",
      "\"HOBO #1\"\n",
      "\"HOBO #2\"\n",
      "\"HOLO ROBOT DEVIL\"\n",
      "\"HOLOBENDER\"\n",
      "\"HOLOFARNSWORTH\"\n",
      "\"HOLOFRY\"\n",
      "\"HOLOHERMES\"\n",
      "\"HOLOLEELA\"\n",
      "\"HOLOORPHANS\"\n",
      "\"HOLOROSEANNE\"\n",
      "\"HOLOVOGEL\"\n",
      "\"HOLOZOIDBERG\"\n",
      "\"HOODED FIGURE #1\"\n",
      "\"HOODED FIGURE #2\"\n",
      "\"HOOKERBOT\"\n",
      "\"HUMAN\"\n",
      "\"HUMAN FRIEND\"\n",
      "\"HUMORBOT 5\"\n",
      "\"HUMOUBOT 5\"\n",
      "\"HUNTER #1\"\n",
      "\"HUNTER #2\"\n",
      "\"HYPERCHICKEN\"\n",
      "\"ICE\"\n",
      "\"IGNER\"\n",
      "\"IHAWK\"\n",
      "\"INFOSPHERE BRAIN\"\n",
      "\"INUITBOT\"\n",
      "\"IPGEE\"\n",
      "\"ITALIAN #1\"\n",
      "\"ITALIAN #2\"\n",
      "\"IZAC\"\n",
      "\"JACK THE RIPPER\"\n",
      "\"JACKIE\"\n",
      "\"JACKSON\"\n",
      "\"JANITOR\"\n",
      "\"JANITORBOT\"\n",
      "\"JEFFERY\"\n",
      "\"JERVIS\"\n",
      "\"JINGLE\"\n",
      "\"JOCKEY\"\n",
      "\"JOE\"\n",
      "\"JOEY\"\n",
      "\"JOHNSON\"\n",
      "\"JOR\"\n",
      "\"JOURNALIST #1\"\n",
      "\"JRRR\"\n",
      "\"JUDGE\"\n",
      "\"JUDGE #1\"\n",
      "\"JUROR #1\"\n",
      "\"JUROR #2\"\n",
      "\"KEGG\"\n",
      "\"KEN\"\n",
      "\"KID\"\n",
      "\"KID #1\"\n",
      "\"KID #2\"\n",
      "\"KID #3\"\n",
      "\"KIDS\"\n",
      "\"KIF\"\n",
      "\"KIRK\"\n",
      "\"KISSENGER\"\n",
      "\"KOENIG\"\n",
      "\"KOJI\"\n",
      "\"KUG\"\n",
      "\"KUG AND ORNIK\"\n",
      "\"KWANZAABOT\"\n",
      "\"LABARBARA\"\n",
      "\"LACKEY\"\n",
      "\"LAMP\"\n",
      "\"LANDLORD #1\"\n",
      "\"LANDLORD #3\"\n",
      "\"LARRY\"\n",
      "\"LEELA\"\n",
      "\"LEELA 1\"\n",
      "\"LEELA 1729\"\n",
      "\"LEG MUTANT\"\n",
      "\"LINCOLN\"\n",
      "\"LINCOLNBOT\"\n",
      "\"LINDA\"\n",
      "\"LITTLE\"\n",
      "\"LITTLE BOY\"\n",
      "\"LITTLE ORPHAN\"\n",
      "\"LIU\"\n",
      "\"LIUBOT\"\n",
      "\"LIUBOT #2\"\n",
      "\"LIUBOT #3\"\n",
      "\"LIUBOT #4\"\n",
      "\"LOU\"\n",
      "\"LRRR\"\n",
      "\"LULABELLE 7\"\n",
      "\"M-5438\"\n",
      "\"MACAULAY CULKON\"\n",
      "\"MAD HATTERBOT\"\n",
      "\"MALACHI\"\n",
      "\"MALACHI JR\"\n",
      "\"MALE ANNOUNCER\"\n",
      "\"MALE SCIENTIST\"\n",
      "\"MALFUNCTIONING EDDIE\"\n",
      "\"MAN\"\n",
      "\"MAN #1\"\n",
      "\"MAN #2\"\n",
      "\"MAN #3\"\n",
      "\"MAN #4\"\n",
      "\"MANDY\"\n",
      "\"MARIO\"\n",
      "\"MARTIAN\"\n",
      "\"MARTIAN #2\"\n",
      "\"MAVIS\"\n",
      "\"MAYOR\"\n",
      "\"MCA\"\n",
      "\"MCNEAL\"\n",
      "\"MECHANIC\"\n",
      "\"MEIDERNEYER\"\n",
      "\"MELLLVAR\"\n",
      "\"MELLLVARS\"\n",
      "\"MERG\"\n",
      "\"MERMAID\"\n",
      "\"MERMAIDS\"\n",
      "\"MERMAN\"\n",
      "\"MIC\"\n",
      "\"MICHELLE\"\n",
      "\"MIDWIFE\"\n",
      "\"MIKE\"\n",
      "\"MILDRED\"\n",
      "\"MILITARY MAN\"\n",
      "\"MINE SPOKESMAN\"\n",
      "\"MOM\"\n",
      "\"MOM CUT\"\n",
      "\"MOMBOT\"\n",
      "\"MONIQUE\"\n",
      "\"MONK #1\"\n",
      "\"MONK #2\"\n",
      "\"MONK #3\"\n",
      "\"MONKEY\"\n",
      "\"MONROEBOT\"\n",
      "\"MONSTER\"\n",
      "\"MOOSE\"\n",
      "\"MORBO\"\n",
      "\"MORGAN\"\n",
      "\"MORIARTY\"\n",
      "\"MORRIS\"\n",
      "\"MOTHER\"\n",
      "\"MR FRY\"\n",
      "\"MR WONG\"\n",
      "\"MRS FRY\"\n",
      "\"MRS GRANT\"\n",
      "\"MRS MELLENGER\"\n",
      "\"MRS WONG\"\n",
      "\"MUGGER\"\n",
      "\"MUNDA\"\n",
      "\"MUTANT\"\n",
      "\"MUTANTS\"\n",
      "\"MYRTLE FU\"\n",
      "\"N.R.A. MAN\"\n",
      "\"NANNYBOT 1\"\n",
      "\"NARRATOR\"\n",
      "\"NATALIE\"\n",
      "\"NAUTILUS\"\n",
      "\"ND-ND\"\n",
      "\"NEPTUNIAN\"\n",
      "\"NEPTUNIAN #1\"\n",
      "\"NEPTUNIAN #2\"\n",
      "\"NEPTUNIAN #3\"\n",
      "\"NEPTUNIAN #4\"\n",
      "\"NEPTUNIANS\"\n",
      "\"NERD\"\n",
      "\"NERD #1\"\n",
      "\"NERD #2\"\n",
      "\"NERD #3\"\n",
      "\"NERD #4\"\n",
      "\"NERDS\"\n",
      "\"NETWORK PRESIDENT\"\n",
      "\"NEUTRAL PRESIDENT\"\n",
      "\"NIBBLER\"\n",
      "\"NIBBLONIAN\"\n",
      "\"NIBBLONIAN CHEF\"\n",
      "\"NICHOLS\"\n",
      "\"NIMOY\"\n",
      "\"NINA\"\n",
      "\"NIXON\"\n",
      "\"NORM\"\n",
      "\"NOTICEABLY F\"\n",
      "\"NUMBER 1\"\n",
      "\"NURSE\"\n",
      "\"NURSE RATCHET\"\n",
      "\"O'BRIEN\"\n",
      "\"O'CONNOR\"\n",
      "\"OCTOPUS\"\n",
      "\"OFFICIAL\"\n",
      "\"OILY\"\n",
      "\"OLD MAN\"\n",
      "\"OLD MAN WATERFALL\"\n",
      "\"OPERATOR\"\n",
      "\"ORANGE ELDER\"\n",
      "\"ORGAN DEALER\"\n",
      "\"ORNIK\"\n",
      "\"OROWHEAT\"\n",
      "\"ORPHAN\"\n",
      "\"OSIRAN\"\n",
      "\"P.A. ANNOUNCER\"\n",
      "\"PAC\"\n",
      "\"PACMAN\"\n",
      "\"PAIN MONSTER\"\n",
      "\"PANUCCI\"\n",
      "\"PARROT\"\n",
      "\"PAST FRY\"\n",
      "\"PATCH CORD ADAMS\"\n",
      "\"PATROL OFFICER #1\"\n",
      "\"PATROL OFFICER #2\"\n",
      "\"PAWNBROKER\"\n",
      "\"PENGUIN #1\"\n",
      "\"PENGUINS\"\n",
      "\"PERSON\"\n",
      "\"PETUNIA\"\n",
      "\"PHOTOGRAPHER\"\n",
      "\"PI-KEA ROBOT\"\n",
      "\"PIG\"\n",
      "\"PIRATE\"\n",
      "\"PLUMBERBOT\"\n",
      "\"POOPENMEYER\"\n",
      "\"POPEIL\"\n",
      "\"POPPLER\"\n",
      "\"PRAMALA\"\n",
      "\"PREACHERBOT\"\n",
      "\"PRIEST\"\n",
      "\"PRIESTBOT\"\n",
      "\"PRIESTS\"\n",
      "\"PROJECT SATAN\"\n",
      "\"PROTESTOR #1\"\n",
      "\"PROTESTOR #2\"\n",
      "\"PROTESTOR #3\"\n",
      "\"PROTOTYPE\"\n",
      "\"Q.T. MCWHISKERS\"\n",
      "\"QUEEN\"\n",
      "\"QUEEQUEG\"\n",
      "\"RALPH KRAMDENBOT\"\n",
      "\"RANDY\"\n",
      "\"RANGER PARK\"\n",
      "\"RAOUL\"\n",
      "\"RAT WOMAN\"\n",
      "\"RAY\"\n",
      "\"RED ELDER\"\n",
      "\"REFEREE\"\n",
      "\"REFRESHMENTBOT\"\n",
      "\"REPOBOT\"\n",
      "\"RICARDO\"\n",
      "\"RIVERS\"\n",
      "\"RJ\"\n",
      "\"ROBBERBOT\"\n",
      "\"ROBERTO\"\n",
      "\"ROBOPUPPY\"\n",
      "\"ROBOT\"\n",
      "\"ROBOT #1\"\n",
      "\"ROBOT #2\"\n",
      "\"ROBOT #3\"\n",
      "\"ROBOT #4\"\n",
      "\"ROBOT #5\"\n",
      "\"ROBOT #6\"\n",
      "\"ROBOT #7\"\n",
      "\"ROBOT #8\"\n",
      "\"ROBOT 1\"\n",
      "\"ROBOT BAILIFF\"\n",
      "\"ROBOT CHEF\"\n",
      "\"ROBOT DEVIL\"\n",
      "\"ROBOT GHOSTS\"\n",
      "\"ROBOT MAYOR\"\n",
      "\"ROBOTS\"\n",
      "\"ROLLERSKATER\"\n",
      "\"RUSTY\"\n",
      "\"SAL\"\n",
      "\"SALESMAN\"\n",
      "\"SALESMAN #1\"\n",
      "\"SALESMAN #2\"\n",
      "\"SALESWOMAN\"\n",
      "\"SALLY\"\n",
      "\"SANDY\"\n",
      "\"SANTA\"\n",
      "\"SCALIA\"\n",
      "\"SCHIFFER\"\n",
      "\"SCIENTIST\"\n",
      "\"SCOOP CHANG\"\n",
      "\"SCOUT LEADER\"\n",
      "\"SCRUFFY\"\n",
      "\"SECURITY GUARD\"\n",
      "\"SERGEANT\"\n",
      "\"SEWERCOM ANNOUNCER\"\n",
      "\"SHATNER\"\n",
      "\"SHELDON\"\n",
      "\"SHERPA\"\n",
      "\"SHIP\"\n",
      "\"SHORE\"\n",
      "\"SHRIMPKIN PRIEST\"\n",
      "\"SHRIMPKINS\"\n",
      "\"SIBLING\"\n",
      "\"SINCLAIR\"\n",
      "\"SINGER\"\n",
      "\"SINGERS\"\n",
      "\"SINGING WIND\"\n",
      "\"SINGLE FEMALE LAWYER\"\n",
      "\"SKIPPER\"\n",
      "\"SLAVE #1\"\n",
      "\"SLAVE #2\"\n",
      "\"SLAVE #3\"\n",
      "\"SLAVES\"\n",
      "\"SLURM ANNOUNCER #2\"\n",
      "\"SLURM MACHINE\"\n",
      "\"SLURM QUEEN\"\n",
      "\"SLURMS\"\n",
      "\"SMALL GLURMO #1\"\n",
      "\"SMALL GLURMO #2\"\n",
      "\"SMARTLY DRESSED MAN\"\n",
      "\"SMITH\"\n",
      "\"SMITTY\"\n",
      "\"SOLDIER #1\"\n",
      "\"SOLICITORBOT\"\n",
      "\"SONG\"\n",
      "\"SOUTER\"\n",
      "\"SPARGLE\"\n",
      "\"STARTER\"\n",
      "\"STATUE\"\n",
      "\"STENOGRAPHER\"\n",
      "\"STEWARD\"\n",
      "\"STEWART\"\n",
      "\"STILT PEOPLE\"\n",
      "\"STOCKBROKER #1\"\n",
      "\"STOCKBROKER #2\"\n",
      "\"STONED GUY\"\n",
      "\"STRIPPERBOT\"\n",
      "\"STUDENT\"\n",
      "\"SUZ\"\n",
      "\"SUZIE\"\n",
      "\"SWEET CLYDE\"\n",
      "\"TAKEI\"\n",
      "\"TANDY\"\n",
      "\"TATE\"\n",
      "\"TATTOO\"\n",
      "\"TEACHER\"\n",
      "\"TECHNICIAN\"\n",
      "\"TEDDY ROOSEVELT\"\n",
      "\"TEENBOT\"\n",
      "\"TELLER\"\n",
      "\"TENANT #1\"\n",
      "\"TENANT #2\"\n",
      "\"TENANT #3\"\n",
      "\"TERRY\"\n",
      "\"THAT GUY\"\n",
      "\"THING #2\"\n",
      "\"THOG\"\n",
      "\"THORIAS\"\n",
      "\"TINNY TIM\"\n",
      "\"TOM SAWYER\"\n",
      "\"TOUR GUIDE\"\n",
      "\"TRASHCAN\"\n",
      "\"TREES\"\n",
      "\"TREKKIE #1\"\n",
      "\"TREKKIE #2\"\n",
      "\"TRICLOPS\"\n",
      "\"TRUCKER #1\"\n",
      "\"TRUCKER #2\"\n",
      "\"TRUMAN\"\n",
      "\"UECKER\"\n",
      "\"UMBRIEL\"\n",
      "\"UMPIRE\"\n",
      "\"UNIT 2013\"\n",
      "\"UNIVERSAL TRANSLATOR\"\n",
      "\"UPGRADER\"\n",
      "\"URL\"\n",
      "\"V.A.P. MAN\"\n",
      "\"VAMPIRE\"\n",
      "\"VAN\"\n",
      "\"VANDAL #1\"\n",
      "\"VANDAL #2\"\n",
      "\"VENDOR\"\n",
      "\"VERNON\"\n",
      "\"VICTOR\"\n",
      "\"VLADIMIRGHOST\"\n",
      "\"VOGEL\"\n",
      "\"VOICE\"\n",
      "\"VYLOET\"\n",
      "\"VYOLET\"\n",
      "\"WAITER\"\n",
      "\"WAITRESS\"\n",
      "\"WALT\"\n",
      "\"WANDA\"\n",
      "\"WASHINGTON\"\n",
      "\"WATERBOT\"\n",
      "\"WATERFALL JR\"\n",
      "\"WATERFALL SR\"\n",
      "\"WELSHY\"\n",
      "\"WENDY\"\n",
      "\"WERNSTROM\"\n",
      "\"WERNSTRUM\"\n",
      "\"WHALE BIOLOGIST\"\n",
      "\"WHALERBOT\"\n",
      "\"WHALERBOTS\"\n",
      "\"WHITEY\"\n",
      "\"WHO ASK MACHINE\"\n",
      "\"WIGGLES\"\n",
      "\"WOMAN\"\n",
      "\"WOMAN #1\"\n",
      "\"WOMAN #2\"\n",
      "\"WOMEN\"\n",
      "\"WORM GUARD #1\"\n",
      "\"WORM GUARD #2\"\n",
      "\"WORM MAYOR\"\n",
      "\"WRIST THING\"\n",
      "\"YANCY\"\n",
      "\"YELLOW ELDER\"\n",
      "\"YOKELBOT\"\n",
      "\"YOUNGER KID\"\n",
      "\"ZAPP\"\n",
      "\"ZOID\"\n",
      "\"ZOIDBERG\"\n",
      "\"ZOIDBERG 1\"\n",
      "\"ZOOKEEPER\"\n"
     ]
    }
   ],
   "source": [
    "def xqueryOverFiles(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        # This only works on Mac / Linux: xq.set_query_base_uri('file://'+getcwd()+'/')\n",
    "        xq.set_query_base_uri(Path('.').absolute().as_uri() + '/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $speakers := $futurama//speak/@who => distinct-values() => sort()\n",
    "let $count := count($speakers)\n",
    "return $speakers\n",
    "\n",
    "   (: ebb: I'm writing in an XQuery comment, and pointing out you can define and return any variable you want in the XQuery zone. :)\n",
    "   (: ebb: Try changing this one to return $speakers instead of the $count variable. :)\n",
    "   (: ebb: We're writing an query-based syntax called FLWOR (pronounced \"flower\") and every FLWOR requires a return statement at the end. :)\n",
    "    \n",
    "''')\n",
    "        r = xq.run_query_to_value()\n",
    "        print(r)  \n",
    "                               \n",
    "xqueryOverFiles(InputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9a52a-1c66-4f2d-abb4-81408479de29",
   "metadata": {},
   "source": [
    "## What's the difference? \n",
    "\n",
    "Notice that you return just one count for the entire collection, not 72 different counts for the speakers in each file.\n",
    "How can we use this? \n",
    "\n",
    "We can get pull information from across the entire collection and find out literally who has the most speeches in the whole series. \n",
    "Take a look at this code. Don't worry if you don't know how to write it yet. I just want to show you for demonstration purposes! \n",
    "What's here is a nearly full \"FLWOR statement\" which stands for :\n",
    "\n",
    "* For\n",
    "* Let\n",
    "* Where\n",
    "* Order by\n",
    "* Return\n",
    "\n",
    "The only things required in a FLWOR statements are L and R. The others give you extra powers like we're seeing here.\n",
    "\n",
    "**IMPORTANT: You're only allowed one return per FLWOR.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3c8f11-81c1-4e3a-a182-9437e50870b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaxonC-HE 12.3 from Saxonica\n",
      "\"FRY:  2684\"\n",
      "\"BENDER:  2360\"\n",
      "\"LEELA:  2117\"\n",
      "\"FARNSWORTH:  990\"\n",
      "\"ZOIDBERG:  581\"\n",
      "\"AMY:  499\"\n",
      "\"HERMES:  408\"\n",
      "\"ZAPP:  336\"\n",
      "\"KIF:  197\"\n",
      "\"CALCULON:  114\"\n"
     ]
    }
   ],
   "source": [
    "def xqueryOverFiles(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        xq.set_query_base_uri(Path('.').absolute().as_uri() + '/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $speakers := $futurama//speak/@who => distinct-values() => sort()\n",
    "let $count := count($speakers)\n",
    "for $sp in $speakers\n",
    "    let $count := $futurama//speak[@who = $sp] => count()\n",
    "    where $count > 100\n",
    "    order by $count descending\n",
    "    return ($sp || ':  ' || $count)\n",
    " \n",
    "''')\n",
    "        r = xq.run_query_to_value()\n",
    "        print(r)  \n",
    "                            \n",
    "\n",
    "xqueryOverFiles(InputPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14970c9-f8e6-4cd5-86ed-32765e274c8c",
   "metadata": {},
   "source": [
    "For this notice how we can move **deliberately** in XQuery from information on the whole collection, to information based on individuals in a series.\n",
    "The counts we're seeing are NOT based on files, but on info about each speaker! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b430fc-4404-4a1c-879f-c6909dba3231",
   "metadata": {},
   "source": [
    "## For statements, measurements, order by, return\n",
    "\n",
    "\n",
    "* Let's choose a character from Futurama who gets a LOT of speeches and use XQuery to pull all their speeches from across the entire collection into one return.\n",
    "The next code block is written to show you how to get all the speeches of one character in the WHOLE collection. You can change this to any other character you wish.\n",
    "* Let's go through each speech individually and meaasure it: \n",
    "* Try out defining a new variable in the XQuery, to use the `string-length()` function, so you can measure the text of the speeches. Try it out!\n",
    "\n",
    "* We're going to write a for statement so we can evaluate each speech, and order our results based on how long the speeches are,\n",
    "     * We'll use the XPath `string-length()` function to measure each speech\n",
    "     * We'll work through an XQuery `for` and `order by`\n",
    "     * Let's see if we can return the speeches from shortest to longest, then try adding the word `descending` to order them longest to shortest!\n",
    "\n",
    "\n",
    "* YOUR TURN: Edit the code below to return some alternative information! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18659ee5-2877-412b-b627-059c5c5c6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xqueryAndNLP(InputPath):\n",
    "    # This time, let's try XQuery over a collection of files:\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        xq.set_query_base_uri(Path('.').absolute().as_uri() + '/')\n",
    "        xq.set_query_content('''\n",
    "let $futurama := collection('futurama-xml/?select=*.xml')\n",
    "let $benderSpeeches := $futurama//speak[@who=\"BENDER\"]\n",
    "let $benderTextsOnly := $benderSpeeches/text() \n",
    "for $bt in $benderTextsOnly\n",
    "   let $length := $bt ! string-length()\n",
    "   where $length gt 20\n",
    "   order by $length descending\n",
    "   return $bt\n",
    "''')\n",
    "        # We started with this: r = xq.run_query_to_value() \n",
    "        # If you use this you need to convert r to a string in Python. r = str(run_query_to_value())\n",
    "        # There's a run_query_to_string() option that's convenient so I'm using it here! \n",
    "        r = xq.run_query_to_string()\n",
    "        return r\n",
    "        # print(r)                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990125f6-ce31-4842-bf8e-6c951412def0",
   "metadata": {},
   "source": [
    "## Experimenting with some functions\n",
    "\n",
    "\n",
    "Remember how we were going to apply some NLP from spaCy? The next part of this exercise is to take the output of this XQuery function and pass it to the spaCY language model!\n",
    "\n",
    "We need XQuery in our function above to return just one string if we want to deliver that to spaCY and NLP tools. The way I left this code, it's returning thousands of strings.\n",
    "\n",
    "* So here's your challenge: Write some code that returns all the text of a different speaker. (Or adjust the code to use in your project.)\n",
    "* The `r` variable is storing the XQuery output. I have updated `r` to be xq.run_query_to_string() which should output a single string. If it syou can convert it to a single string in Python with `str()`.\n",
    "* Then make sure it's returning a single string when you print(r). You may need to convert `r` \n",
    "* **Write some new code** that delivers this single string to be processed with spaCy in some way.\n",
    "    * You can build your code in a new cell block below this one.\n",
    "    *  You'll probably want to review [this spaCy NLP assignment](https://github.com/newtfire/textAnalysis-Hub/blob/main/python-nlp-exercise1.md#write-some-python-code-to-do-the-following)\n",
    "    * Write your code to return any information of interest from spaCy, following the spaCy documentation as we did in that earlier assignment! Try looking for one or two different kinds of language. What are the most popular verbs, adjectives, nouns? Try out the NER (named entity recognition)...Write your code in your copy of this Jupyter Notebook to complete this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4574b646-79c0-459b-8f84-17f053e81108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaxonC-HE 12.3 from Saxonica\n",
      "Lemma frequency Counter({'get': 214, 'go': 175, 'do': 115, 'have': 115, 'say': 90, 'know': 89, 'make': 84, 'come': 79, 'look': 74, 'let': 72, 'think': 69, 'take': 56, 'want': 52, 'see': 52, 'love': 42, 'mean': 41, 'need': 39, 'kill': 38, 'wait': 34, 'give': 34, 'be': 34, 'call': 34, 'try': 33, 'feel': 31, 'tell': 31, 'use': 27, 'like': 27, 'find': 25, 'stop': 25, 'keep': 21, 'hear': 20, 'bend': 20, 'save': 19, 'live': 19, 'wanna': 19, 'remember': 19, 'steal': 18, 'eat': 18, 'build': 18, 'help': 17, 'shut': 17, 'forget': 17, 'put': 17, 'work': 17, 'run': 16, 'win': 16, 'guess': 15, 'happen': 15, 'die': 14, 'hurt': 13, 'meet': 13, 'believe': 13, 'check': 12, 'hit': 12, 'move': 12, 'bring': 12, 'leave': 12, 'ask': 11, 'care': 11, 'talk': 11, 'show': 11, 'turn': 10, 'break': 10, 'hold': 10, 'start': 10, 'hate': 10, 'watch': 10, 'mind': 10, 'bite': 10, 'miss': 10, 'drink': 9, 'walk': 9, 'hope': 9, 'pay': 9, 'cook': 9, 'comin': 9, 'pick': 9, 'fight': 9, 'lose': 8, 'stink': 8, 'understand': 8, 'count': 8, 'blow': 8, 'quit': 8, 'kick': 8, 'catch': 8, 'beat': 8, 'stay': 8, 'worry': 8, 'learn': 8, 'sit': 7, 'sing': 7, 'sound': 7, 'listen': 7, 'wish': 7, 'throw': 6, 'suck': 6, 'wonder': 6, 'suppose': 6, 'teach': 6, 'send': 6, 'bet': 6, 'thank': 6, 'cheer': 6, 'name': 6, 'gimmie': 6, 'fix': 6, 'seem': 6, 'stick': 6, 'smoke': 5, 'enjoy': 5, 'allow': 5, 'read': 5, 'hang': 5, 'ride': 5, 'screw': 5, 'kiss': 5, 'bear': 5, 'dunno': 5, 'cry': 5, 'laugh': 5, 'date': 5, 'deliver': 5, 'knock': 5, 'write': 5, 'destroy': 5, 'explain': 5, 'wear': 5, 'touch': 5, 'burn': 5, 'hide': 5, 'blame': 4, 'set': 4, 'fall': 4, 'prefer': 4, 'cover': 4, 'solve': 4, 'change': 4, 'swear': 4, 'pretend': 4, 'curse': 4, 'bake': 4, 'follow': 4, 'drop': 4, 'figure': 4, 'pull': 4, 'taste': 4, 'cost': 4, 'shoot': 4, 'step': 4, 'demand': 4, 'fly': 4, 'bone': 3, 'express': 3, 'create': 3, 'lay': 3, 'going': 3, 'notice': 3, 'carry': 3, 'owe': 3, 'share': 3, 'end': 3, 'wash': 3, 'waste': 3, 'kid': 3, 'become': 3, 'shove': 3, 'admire': 3, 'melt': 3, 'cut': 3, 'pass': 3, 'stand': 3, 'pump': 3, 'swing': 3, 'cross': 3, 'slow': 3, 'grow': 3, 'tempt': 3, 'program': 3, 'play': 3, 'lie': 3, 'float': 3, 'smell': 3, 'strike': 3, 'clean': 3, 'wrap': 3, 'lift': 3, 'round': 3, 'pray': 3, 'begin': 3, 'grab': 3, 'interfere': 3, 'hallucinate': 3, 'plan': 3, 'agree': 3, 'party': 3, 'own': 3, 'pound': 3, 'gettin': 3, 'dress': 3, 'sleep': 3, 'pardon': 3, 'buy': 3, 'travel': 3, 'guarantee': 3, 'act': 3, 'spend': 2, 'damn': 2, 'push': 2, 'frame': 2, 'score': 2, 'accept': 2, 'behold': 2, 'appreciate': 2, 'escape': 2, 'face': 2, 'absorb': 2, 'bounce': 2, 'complain': 2, 'judge': 2, 'deserve': 2, 'speak': 2, 'line': 2, 'block': 2, 'force': 2, 'activate': 2, 'shine': 2, 'disguise': 2, 'squeal': 2, 'tie': 2, 're': 2, 'train': 2, 'point': 2, 'hammer': 2, 'fortify': 2, 'hug': 2, 'shake': 2, 'intend': 2, 'involve': 2, 'ruin': 2, 'order': 2, 'rebel': 2, 'pop': 2, 'worship': 2, 'experience': 2, 'cram': 2, 'hire': 2, 'rig': 2, 'fill': 2, 'celebrate': 2, 'free': 2, 'present': 2, 'signal': 2, 'whisper': 2, 'sell': 2, 'nest': 2, 'wake': 2, 'add': 2, 'leak': 2, 'avenge': 2, 'visit': 2, 'tear': 2, 'annoy': 2, 'lead': 2, 'trade': 2, 'chop': 2, 'wreck': 2, 'survive': 2, 'return': 2, 'dance': 2, 'defeat': 2, 'wet': 2, 'appear': 2, 'gather': 2, 'admit': 2, 'punch': 2, 'mess': 2, 'cause': 2, 'censor': 2, 'hand': 2, 'joke': 2, '-': 2, 'trust': 2, 'invite': 2, 'scuse': 2, 'recall': 2, 'toss': 2, 'deal': 2, 'retire': 2, 'prepare': 2, 'open': 2, 'close': 2, 'pet': 2, 'hurry': 2, 'jerk': 2, 'bendere': 2, 'volunteer': 2, 'head': 2, 'vote': 2, 'scream': 2, 'Put': 2, 'weep': 2, 'pende': 2, 'fate': 1, 'drift': 1, 'perfect': 1, 'commit': 1, 'expose': 1, 'rest': 1, 'chuck': 1, 'would': 1, 'balance': 1, 'bombard': 1, 'whiz': 1, 'decline': 1, 'supply': 1, 'vanish': 1, 'exile': 1, 'affect': 1, 'quote': 1, 'forbid': 1, 'respect': 1, 'disappoint': 1, 'compare': 1, 'degenerate': 1, 'fullfill': 1, 'damage': 1, 'fake': 1, 'afford': 1, 'succeed': 1, 'convince': 1, 'seal': 1, 'march': 1, 'settle': 1, 'mention': 1, 'doom': 1, 'yearn': 1, 'cheapen': 1, 'motivate': 1, 'whip': 1, 'construct': 1, 'arrange': 1, 'time': 1, 'purchase': 1, 'buck': 1, 'wiggle': 1, 'mistreat': 1, 'consider': 1, 'rise': 1, 'personalise': 1, 'slave': 1, 'dream': 1, 'transcend': 1, 'invent': 1, 'inflate': 1, 'launch': 1, 'last': 1, 'trick': 1, 'interrupt': 1, 'rattle': 1, 'drain': 1, 'm': 1, 'blast': 1, 'flame': 1, 'label': 1, 'bind': 1, 'slice': 1, 'peruse': 1, 'select': 1, 'tag': 1, 'burst': 1, 'moron': 1, 'refill': 1, 'crap': 1, 'instal': 1, 'gag': 1, 'engulf': 1, 'disappear': 1, 'methink': 1, 'require': 1, 'behave': 1, 'charge': 1, 's': 1, 'puke': 1, 'smack': 1, 'siphon': 1, 'assume': 1, 'toy': 1, 'collide': 1, 'excuse': 1, 'plate': 1, 'overcome': 1, 'creep': 1, '\"confidence': 1, 'fetch': 1, 'relate': 1, 'base': 1, 'welcome': 1, 'relax': 1, 'strut': 1, 'tender': 1, 'ste': 1, 'bush': 1, 'organise': 1, 'support': 1, 'pledge': 1, 'promote': 1, 'wire': 1, 'singe': 1, 'croak': 1, 'unplug': 1, 'rob': 1, 'power': 1, 'explode': 1, 'exist': 1, 'snag': 1, 'matter': 1, 'register': 1, 'suffer': 1, 'regret': 1, 'bug': 1, 'humiliate': 1, 'lodge': 1, 'wallow': 1, 'outrage': 1, 'skidaddle': 1, 'meld': 1, 'swarm': 1, 'memorise': 1, 'tick': 1, 'deface': 1, 'restore': 1, 'cheste': 1, 'belly': 1, 'greet': 1, 'improve': 1, 'please': 1, 'lord': 1, 'equip': 1, 'fast': 1, 'embarrass': 1, 'pimp': 1, 'amount': 1, 'graduate': 1, 'omit': 1, 'monogramme': 1, 'shanghai': 1, 'defend': 1, 'oughta': 1, 'poke': 1, 'workin': 1, 'remind': 1, 'condition': 1, 'fart': 1, 'paint': 1, 'stipend': 1, 'collect': 1, 'strap': 1, 'juicer': 1, 'rake': 1, 'tend': 1, 'scrape': 1, 'rotate': 1, 'engage': 1, 'stage': 1, 'chronicle': 1, 'propose': 1, 'nag': 1, 'lick': 1, 'talkin': 1, 'schedule': 1, 'stem': 1, 'seduce': 1, 'pawn': 1, 'boom': 1, 'drive': 1, 'void': 1, 'shrink': 1, 'ditch': 1, 'lighten': 1, 'bury': 1, 'outwit': 1, 'design': 1, 'land': 1, 'empty': 1, 'resume': 1, 'parasaile': 1, 'rhyme': 1, 'refuse': 1, 'rid': 1, 'craft': 1, 'dare': 1, 'fork': 1, 'preach': 1, 'stone': 1, 'challenge': 1, 'sink': 1, 'bang': 1, 'rock': 1, 'indicate': 1, 'evolve': 1, 'peetere': 1, 'achieve': 1, 'eject': 1, 'mortify': 1, 'shell': 1, 'woope': 1, 'dig': 1, 'major': 1, 'opener': 1, 'suspect': 1, 'earn': 1, 'regard': 1, 'serve': 1, 'occur': 1, 'breed': 1, 'pollute': 1, 'belong': 1, 'cripple': 1, 'revert': 1, 'mug': 1, 'qualify': 1, 'donate': 1, 'switch': 1, 'interface': 1, 'bus': 1, 'freeze': 1, 'recommend': 1, 'fry': 1, 'hitch': 1, 'hoot': 1, 'swell': 1, 'Lousy': 1, 'panic': 1, 'grill': 1, 'offer': 1, 'lucke': 1, 'jack': 1, 'swim': 1, 'cheat': 1, 'malfunction': 1, 'cancel': 1, 'whale': 1, 'glow': 1, 'sneak': 1, 'sanctify': 1, 'convert': 1, 'torment': 1, 'kafooble': 1, 'arrive': 1, 'dump': 1, 'weld': 1, 'modify': 1, 'assure': 1, 'wipe': 1, 'treat': 1, 'stab': 1, 'tote': 1, 'liven': 1, 'emerge': 1, 'sign': 1, 'draw': 1, 'record': 1, 'lock': 1, 'decay': 1, 'inspire': 1, 'unload': 1, 'wage': 1, 'reflect': 1, 'complete': 1, 'misunderstand': 1, 'lend': 1, 'perform': 1, 'summarise': 1, 'whack': 1, 'handle': 1, 'regain': 1, 'receive': 1, 'appetise': 1, 'spill': 1, 'shrimptoast': 1, 'antique': 1, 'overrule': 1, 'forgot': 1, 'suggest': 1, 'speed': 1, 'describe': 1, 'finish': 1, 'rip': 1, 'bastard': 1, 'yell': 1, 'override': 1, 'reprogram': 1, 'erase': 1, 'release': 1, 'trouble': 1, 'discuss': 1, 'Quit': 1, 'strangle': 1, 'direct': 1, 'jump': 1, 'accomplish': 1, 'guide': 1, 'tune': 1, 'scratch': 1, 'bust': 1, 'pot': 1, 'expect': 1, 'pour': 1, 'choose': 1, 'realise': 1, 'skyrocket': 1, 'prove': 1, 'pinken': 1, 'chew': 1, 'reboot': 1, 'drag': 1, 'introduce': 1, 'commence': 1, 'rumble': 1, 'haunt': 1, 'gamble': 1, 'stifle': 1, 'upgrade': 1, 'cur': 1, 'puff': 1, 'calm': 1, 'makin': 1, 'mix': 1, 'insist': 1, 'insert': 1, 'cure': 1, 'sweat': 1, 'spay': 1, 'lookin': 1, 'surface': 1, 'join': 1, 'remove': 1, 'crack': 1, 'crush': 1, 'steer': 1, 'load': 1, 'hock': 1, 'mush': 1, 'fish': 1, 'stir': 1, 'fail': 1, 'squeeze': 1, 'freeload': 1, 'inhabit': 1, 'honour': 1, 'breathe': 1, 'protest': 1, 'clone': 1, 'choke': 1, 'brew': 1, 'insult': 1, 'foresee': 1, 'reach': 1, 'tis': 1, 'rescue': 1, 'twit': 1, 'fire': 1, 'assist': 1, 'loot': 1, 'snatch': 1, 'raise': 1, 'boil': 1, 'convict': 1, 'deploy': 1, 'trap': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "inputstring = xqueryAndNLP(InputPath)\n",
    "# start playing with spaCy and nlp:\n",
    "benderWords = nlp(inputstring)\n",
    "# print(benderWords)\n",
    "\n",
    "\n",
    "BenderLemmas = []\n",
    "for token in benderWords:\n",
    "    if token.pos_ == \"VERB\":\n",
    "        lemma = token.lemma_\n",
    "        BenderLemmas.append(lemma)\n",
    "\n",
    "# Okay, we'll use python's Counter() find out how frequently each verb lemma shows up in the entire verb list.\n",
    "# Counter() removes duplicates and counts the number of times something appears. \n",
    "# And it outputs a dictionary of key:value pairs already sorted from highest to lowet count.\n",
    "\n",
    "lemmaFreq = Counter(BenderLemmas)\n",
    "\n",
    "print(f\"Lemma frequency {lemmaFreq}\")\n",
    "\n",
    "# We can even calculate the percentage each verb is used.\n",
    "# The totalVerbCount will be the length of the BenderLemmas list.\n",
    "\n",
    "totalVerbCount = len(BenderLemmas) \n",
    "# print(f\"total verb count: {totalVerbCount}\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6635ec-f023-4df9-9462-6ee4602c85fb",
   "metadata": {},
   "source": [
    "## Plotting some output in SVG\n",
    "Here's how to do this with the seaborn library. You can work with a range of palettes here optimized in different ways for displaying graph data.\n",
    "First some installs. matplotlib and seaborn libraries work together when we start plotting. These are some frequently used visualization libraries in Python, and you can customize them for display in jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc53804-9567-4d4c-80ca-f1cd81f911b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy \n",
    "#!pip install seaborn\n",
    "#!pip install matplotlib\n",
    "\n",
    "# Counter is an amazing Python module: it's going to save us some lines of code.\n",
    "# We'll use it when we want to get count information of how often distinct forms of a word occur in our colleciton. \n",
    "# Fun things to do with Counter: https://realpython.com/python-counter/#plotting-categorical-data-with-matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb2780-18d3-456d-94f6-0b4d60fa4e67",
   "metadata": {},
   "source": [
    "### How much to plot? And how to display? \n",
    "If we're displaying in a Jupyter Notebook, there are some display configurations to set, marked with a `%` in the next cell. \n",
    "\n",
    "We don't want to plot every last word here. But we have a lot of data, so we can experiment\n",
    "To access data in our Counter list and keep it organized from highest to lowest value, we use `most_common()`.\n",
    "Then we can slice it to store however many we want to plot. [:10] would plot the first 11 values since python starts counting from zero.\n",
    "\n",
    "### Seaborn Library \n",
    "This library is a favorite among developers because it's easy to use and configure. \n",
    "\n",
    "#### YOUR ASSIGNMENT \n",
    "Change the display of data in the following ways:\n",
    "* Change the selection and amount of data being plotted\n",
    "* Change the color / appearance of the plot on consulting Seaborn's documentation on color palettes: https://seaborn.pydata.org/tutorial/color_palettes.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60aa93f-3b4b-4db6-9f17-59af8e889a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't want to plot every last word here. But we have a lot of data, so we can experiment\n",
    "# To access data in our Counter list and keep it organized from highest to lowest value, we use `most_common()`.\n",
    "# Then we can slice it to store however many we want to plot. [:10] would plot the first 11 values since python starts counting from zero.\n",
    "\n",
    "mostCommon = dict(lemmaFreq.most_common()[:44])\n",
    "print(f\"mostCommon Lemmas {mostCommon}\")\n",
    "\n",
    "# Turns out after some tinkering that the seaborn library wants to collect its x and y values from lists. \n",
    "# So I'm just unpacking the values and keys, and checking to make sure they remain in their dictionary order here. \n",
    "counts = list(mostCommon.values())\n",
    "lems = list(mostCommon.keys())\n",
    "print(counts)\n",
    "print(lems)\n",
    "\n",
    "# This is to help matplotlib to display plots inline in the Jupyter Notebook\n",
    "%matplotlib inline\n",
    "# Set figure size configuration\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "# Create bar plot using seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.barplot(x=counts, y=lems, palette=\"magma\")\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Words')\n",
    "plt.title('Most Common Lemmas')\n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc77752-e826-4949-b334-0e934f4322ed",
   "metadata": {},
   "source": [
    "# Check out the SVG :-)\n",
    "The next cell is just here to show you what SVG code looks like \"under the hood\": SVG is a kind of XML, and we can output it programmatically to make shapes and lines and apply colors based on data. Click on the cell to see what the code looks like underneath: we'll be exploring this code in more detail soon! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99206dc3-8487-4153-be7b-f962a40148b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simple.svg\n",
    "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"100%\" height=\"100%\">\n",
    "    <desc><!--You could write a description of this SVG here.--></desc>\n",
    "    <g alignment-baseline=\"baseline\" transform=\"translate (25, 100)\">\n",
    "        <!--The \"g\" element just lets us *group* stuff together. -->\n",
    "        <circle cx=\"320\" cy=\"80\" r=\"50\" stroke=\"red\" fill=\"orange\" stroke-width=\"4\"/>  \n",
    "     <circle cx=\"250\" cy=\"150\" r=\"100\" stroke=\"red\" fill=\"purple\" stroke-width=\"4\"/>  \n",
    "        \n",
    "       \n",
    "        \n",
    "        <!--<line x1=\"25\" y1=\"-5\" x2=\"500\" y2=\"500\" stroke=\"red\" stroke-width=\"3\"/>-->\n",
    "        \n",
    "        <line x1=\"25\" y1=\"300\" x2=\"700\" y2=\"300\" stroke=\"purple\" stroke-width=\"20\"/>\n",
    "       <!--line above is the x axis of my graph -->\n",
    "        \n",
    "        <line x1=\"25\" y1=\"300\" x2=\"25\" y2=\"0\" stroke=\"green\" stroke-width=\"10\"/>\n",
    "        \n",
    "        <line x1=\"25\" y1=\"250\" x2=\"700\" y2=\"250\" stroke=\"purple\" stroke-width=\"2\"/>\n",
    "        \n",
    "        <text x=\"15\" y=\"230\" fill=\"purple\" style=\"font-family:serif;font-size:15px; writing-mode: tb; glyph-orientation-vertical: 5\">50</text>\n",
    "        \n",
    "        <line x1=\"25\" y1=\"100\" x2=\"700\" y2=\"100\" stroke=\"purple\" stroke-width=\"2\"/>\n",
    "        <text x=\"15\" y=\"90\" fill=\"purple\" style=\"font-family:sans-serif;font-size:15px; writing-mode: tb; glyph-orientation-horizontal: 5\">75</text>\n",
    "    </g>\n",
    "</svg>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853a94f-f358-4ea9-9643-1e1d46ffc231",
   "metadata": {},
   "source": [
    "<img src=\"simple.svg\" height=\"100%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd8e90-531a-49c9-9efd-f16621976c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
